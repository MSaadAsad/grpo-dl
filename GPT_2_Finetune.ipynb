{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b95c80e02efa470088ba30768da82a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7f504f708e94eb48b47e37cfc1c1ada",
              "IPY_MODEL_196835a82a754594bfb1619689cb4a77",
              "IPY_MODEL_cf7fbb3198f9474da841e6ad0ef2b183"
            ],
            "layout": "IPY_MODEL_e4ef5790c25744feb37c07ff3911954f"
          }
        },
        "d7f504f708e94eb48b47e37cfc1c1ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246f6e195a7148e784c622deb402d291",
            "placeholder": "​",
            "style": "IPY_MODEL_b9daf38e138b437ea165cfe95a0635b6",
            "value": "Map: 100%"
          }
        },
        "196835a82a754594bfb1619689cb4a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71049b0cd944d0bb73c510514f3ee2a",
            "max": 747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38e64d1d922b43d08ab12dcc6c3d1281",
            "value": 747
          }
        },
        "cf7fbb3198f9474da841e6ad0ef2b183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e77fa1c989452e8717046d103edcd2",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9c612d464749ce8cca0d8916ce78ec",
            "value": " 747/747 [00:00&lt;00:00, 1064.63 examples/s]"
          }
        },
        "e4ef5790c25744feb37c07ff3911954f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "246f6e195a7148e784c622deb402d291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9daf38e138b437ea165cfe95a0635b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e71049b0cd944d0bb73c510514f3ee2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e64d1d922b43d08ab12dcc6c3d1281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7e77fa1c989452e8717046d103edcd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9c612d464749ce8cca0d8916ce78ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55c7bfb6591f44fe9d9802b196732dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a11bbb2ce52642c1843ac2d939b3478f",
              "IPY_MODEL_778e656fe12246fcae6cf68cc28c3644",
              "IPY_MODEL_ed84bb12d530497ea54b6ef0711a9935"
            ],
            "layout": "IPY_MODEL_5ca21cec12d8465c99757b6aee11db29"
          }
        },
        "a11bbb2ce52642c1843ac2d939b3478f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a0992804824abcb357e7a22c193eb0",
            "placeholder": "​",
            "style": "IPY_MODEL_ef51f47adb9446d49692f49ccee32e9b",
            "value": "Map: 100%"
          }
        },
        "778e656fe12246fcae6cf68cc28c3644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57122d3022fb4747ba63c7688de96256",
            "max": 132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e24e4ebdb8d54cba987b89a3288049b5",
            "value": 132
          }
        },
        "ed84bb12d530497ea54b6ef0711a9935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7564418e1da4e5ca4648c504f42ee48",
            "placeholder": "​",
            "style": "IPY_MODEL_4fccd155e23c48d19d8bc2de33e0f100",
            "value": " 132/132 [00:00&lt;00:00, 614.74 examples/s]"
          }
        },
        "5ca21cec12d8465c99757b6aee11db29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a0992804824abcb357e7a22c193eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef51f47adb9446d49692f49ccee32e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57122d3022fb4747ba63c7688de96256": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24e4ebdb8d54cba987b89a3288049b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7564418e1da4e5ca4648c504f42ee48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fccd155e23c48d19d8bc2de33e0f100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b02030791ce46488e2981aae2df618d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9e9b9ccce4243c0b75d4ab2dacf1e29",
              "IPY_MODEL_794b83567f7442c9b969215fdc571e5b",
              "IPY_MODEL_542ddd69dbda4b25a7947e491b589eb9"
            ],
            "layout": "IPY_MODEL_6334a32c6a824af29b10a150ae368868"
          }
        },
        "c9e9b9ccce4243c0b75d4ab2dacf1e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9446ecdd8164ea9a1fbd2c1b10bf2f4",
            "placeholder": "​",
            "style": "IPY_MODEL_de1fc501662a4890951041fd1a3dbfe1",
            "value": "Batched Inference: 100%"
          }
        },
        "794b83567f7442c9b969215fdc571e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9ef8ed14f749d1bc8ef395dbdf9566",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19c7b92a6e534a8d952f86ab5553edd8",
            "value": 9
          }
        },
        "542ddd69dbda4b25a7947e491b589eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0257879afb4ed0b664179c014a44db",
            "placeholder": "​",
            "style": "IPY_MODEL_d15eb8d1dc78404293b2d57fcd5ff1f2",
            "value": " 9/9 [00:55&lt;00:00,  6.10s/it]"
          }
        },
        "6334a32c6a824af29b10a150ae368868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9446ecdd8164ea9a1fbd2c1b10bf2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1fc501662a4890951041fd1a3dbfe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d9ef8ed14f749d1bc8ef395dbdf9566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c7b92a6e534a8d952f86ab5553edd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca0257879afb4ed0b664179c014a44db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15eb8d1dc78404293b2d57fcd5ff1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21a9e5d55ebb4de09eda49239ca6006d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9c6987b89d3443780b7b149aa93cd2e",
              "IPY_MODEL_f0c7a50a03934ae59d33c20715003637",
              "IPY_MODEL_9a2a2cf8d483493aafafcc06930040fe"
            ],
            "layout": "IPY_MODEL_6cf438d8266342d2af492310588716a8"
          }
        },
        "a9c6987b89d3443780b7b149aa93cd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d75b81658284476f9c852380ef742a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_015a824aab784952afd25f0421c00677",
            "value": "Epochs: 100%"
          }
        },
        "f0c7a50a03934ae59d33c20715003637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eafabd003044cb09519679cdd2ee08a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51b6af7bbd95497a9b71a9631d522dc4",
            "value": 1
          }
        },
        "9a2a2cf8d483493aafafcc06930040fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b9bcd8fc8944f0aec55f97f7fdf3e4",
            "placeholder": "​",
            "style": "IPY_MODEL_0cb9969b5aea402cb43b5de2757a24a1",
            "value": " 1/1 [1:02:08&lt;00:00, 3728.12s/it]"
          }
        },
        "6cf438d8266342d2af492310588716a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75b81658284476f9c852380ef742a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015a824aab784952afd25f0421c00677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eafabd003044cb09519679cdd2ee08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b6af7bbd95497a9b71a9631d522dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16b9bcd8fc8944f0aec55f97f7fdf3e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb9969b5aea402cb43b5de2757a24a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787e59b8472146d6bdf9fd179ef323a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eb57d47d0f2413787c0e8ea995c38e9",
              "IPY_MODEL_d58b1433dea24fd0a8e1318d53c8e3fc",
              "IPY_MODEL_a736e02d13cd4f71ab88ce8a37e45116"
            ],
            "layout": "IPY_MODEL_59d1e560f5d94004a9bface2631b33d8"
          }
        },
        "8eb57d47d0f2413787c0e8ea995c38e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c19b85adcf104ea88f0231a36cf53039",
            "placeholder": "​",
            "style": "IPY_MODEL_aa44c371c99f4d659f7f94a65e537d5d",
            "value": "Batches: 100%"
          }
        },
        "d58b1433dea24fd0a8e1318d53c8e3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c12181b4be5943d9a865ef345906a3f9",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91197708d6aa41e293db8f2516916b06",
            "value": 168
          }
        },
        "a736e02d13cd4f71ab88ce8a37e45116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b93bedfa389b425792546b74b7cec9e7",
            "placeholder": "​",
            "style": "IPY_MODEL_294d3e0083224a31baa3e72157f5e459",
            "value": " 168/168 [1:02:08&lt;00:00, 22.16s/it]"
          }
        },
        "59d1e560f5d94004a9bface2631b33d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c19b85adcf104ea88f0231a36cf53039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa44c371c99f4d659f7f94a65e537d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c12181b4be5943d9a865ef345906a3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91197708d6aa41e293db8f2516916b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b93bedfa389b425792546b74b7cec9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294d3e0083224a31baa3e72157f5e459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe5059e595514912a20de6fed1a229fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_549e7890cdd74271885902a3ecb84257",
              "IPY_MODEL_45e6318493524b4ab684a73b70dd83f9",
              "IPY_MODEL_0cffbc42422641c6bf71361c45af865e"
            ],
            "layout": "IPY_MODEL_2d22057591e6445d9af4e2f97307d7e1"
          }
        },
        "549e7890cdd74271885902a3ecb84257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc86fa6c31e242b793e7edb485ffb7d4",
            "placeholder": "​",
            "style": "IPY_MODEL_f28c5b4e391c44758af0113833cf54e4",
            "value": "GRPO Inference:   0%"
          }
        },
        "45e6318493524b4ab684a73b70dd83f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c40021d20b4174838ceab64d07159d",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dd6c8ba11db4d88a6be1ce954d9505c",
            "value": 0
          }
        },
        "0cffbc42422641c6bf71361c45af865e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2788ed6f018843d08627411af34dbac8",
            "placeholder": "​",
            "style": "IPY_MODEL_e17498c6deac4efe87fb98753c00b460",
            "value": " 0/5 [00:00&lt;?, ?it/s]"
          }
        },
        "2d22057591e6445d9af4e2f97307d7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc86fa6c31e242b793e7edb485ffb7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28c5b4e391c44758af0113833cf54e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22c40021d20b4174838ceab64d07159d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd6c8ba11db4d88a6be1ce954d9505c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2788ed6f018843d08627411af34dbac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17498c6deac4efe87fb98753c00b460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRGhvgN2AIIR",
        "outputId": "fad34a4c-87c1-4569-a686-e51d78f99bbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    GenerationConfig\n",
        ")\n",
        "import kagglehub\n",
        "import math\n",
        "import re\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "zoAuf7te8wQI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ-Uwlyg8VXZ",
        "outputId": "93697ad3-4d82-41ef-db95-bd2bdda95f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/thedevastator/grade-school-math-8k-q-a/versions/2\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "path = kagglehub.dataset_download(\"thedevastator/grade-school-math-8k-q-a\")\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Load the Tokenizer\n",
        "# ----------------------------\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-large', padding_side='left')\n",
        "\n",
        "# Add/modify special tokens to handle chat format better\n",
        "special_tokens_dict = {\n",
        "    'pad_token': '[PAD]',\n",
        "    'bos_token': '<|im_start|>',\n",
        "    'eos_token': '<|im_end|>',\n",
        "    'sep_token': '<|im_sep|>',\n",
        "    'additional_special_tokens': [\n",
        "        '####'\n",
        "    ]\n",
        "}\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# ----------------------------\n",
        "# Load the Model\n",
        "# ----------------------------\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Configure model settings\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.bos_token_id = tokenizer.bos_token_id\n",
        "model.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Set up generation config\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.1,\n",
        ")\n",
        "model.generation_config = generation_config"
      ],
      "metadata": {
        "id": "eB9vQu622dYr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and combine all CSV files\n",
        "base_path = \"/root/.cache/kagglehub/datasets/thedevastator/grade-school-math-8k-q-a/versions/2\"\n",
        "files = ['main_train.csv', 'main_test.csv']\n",
        "\n",
        "max_tokens = 0\n",
        "max_example = None\n",
        "max_file = None\n",
        "\n",
        "for file in files:\n",
        "    df = pd.read_csv(os.path.join(path, file))\n",
        "\n",
        "    # Count tokens for questions and answers separately\n",
        "    question_tokens = df['question'].apply(lambda x: len(tokenizer.encode(str(x))))\n",
        "    answer_tokens = df['answer'].apply(lambda x: len(tokenizer.encode(str(x))))\n",
        "\n",
        "    print(f\"\\n{file}:\")\n",
        "    print(f\"Questions - Max tokens: {question_tokens.max()}, Mean: {question_tokens.mean():.1f}\")\n",
        "    print(f\"Answers - Max tokens: {answer_tokens.max()}, Mean: {answer_tokens.mean():.1f}\")\n",
        "\n",
        "    # Find max examples\n",
        "    max_q_idx = question_tokens.idxmax()\n",
        "    max_a_idx = answer_tokens.idxmax()\n",
        "\n",
        "    print(f\"\\nLongest question ({question_tokens.max()} tokens):\")\n",
        "    print(df['question'].iloc[max_q_idx])\n",
        "    print(f\"\\nLongest answer ({answer_tokens.max()} tokens):\")\n",
        "    print(df['answer'].iloc[max_a_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7zbMWGy8Yd3",
        "outputId": "e7a7893e-1f4c-433c-971d-a0dcfc0a48ff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "main_train.csv:\n",
            "Questions - Max tokens: 213, Mean: 55.2\n",
            "Answers - Max tokens: 342, Mean: 95.3\n",
            "\n",
            "Longest question (213 tokens):\n",
            "Hasan is packing up his apartment because he’s moving across the country for a new job. He needs to ship several boxes to his new home. The movers have asked that Hasan avoid putting more than a certain weight in pounds in any cardboard box. The moving company has helpfully provided Hasan with a digital scale that will alert him if a package is too heavy. Hasan is in the kitchen, and he fills a cardboard box with 38 dinner plates. When he checks the box, the scale reports his box is too heavy. Hasan knows each of his plates weighs 10 ounces. He removes a single plate from the box and checks the movers’ scale again. The scale reports his box is still too heavy. Hasan repeats the process again and again. When he has removed enough plates, the movers’ scale shows the box is now an acceptable weight for shipping. Hasan deduces that each shipping box can hold 20 pounds before the scale says the box is too heavy.  How many plates did Hasan need to remove from the shipping box?\n",
            "\n",
            "Longest answer (342 tokens):\n",
            "First figure out how many hours each worker works per month by multiplying the number of days they work by the number of hours a day they work: 25 days * 8 hours/day = <<25*8=200>>200 hours\n",
            "Then calculate how much one warehouse worker makes per month by multiplying their hourly rate by the number of hours they work: 200 hours * $15/hour = $<<200*15=3000>>3000\n",
            "Then multiply that number by 4 to find out how much all the warehouse workers make: $3000/worker * 4 workers = $<<3000*4=12000>>12,000\n",
            "Now multiply the hours each manager works (also 200) by their hourly wage to find out how much one manager makes per month: 200 hours * $20/hour = $<<200*20=4000>>4,000\n",
            "Now multiply one manager's wages by the number of managers (2) to find their total wage amount: $4,000/manager * 2 managers = $<<4000*2=8000>>8,000\n",
            "Now add the wages for the managers and the workers to find the total cost of the wages: $8,000 + $12,000 = $<<8000+12000=20000>>20,000\n",
            "Now multiply the total wage bill by 10% to find how much the FICA taxes are: $20,000 * .1 = $<<20000*.1=2000>>2,000\n",
            "Now add the total wage bill to the total tax amount to find the grand total: $2,000 + $20,000 = $<<2000+20000=22000>>22,000\n",
            "#### 22000\n",
            "\n",
            "main_test.csv:\n",
            "Questions - Max tokens: 182, Mean: 56.8\n",
            "Answers - Max tokens: 302, Mean: 97.8\n",
            "\n",
            "Longest question (182 tokens):\n",
            "Paul is at a train station and is waiting for his train. He isn't sure how long he needs to wait, but he knows that the fourth train scheduled to arrive at the station is the one he needs to get on. The first train is scheduled to arrive in 10 minutes, and this train will stay in the station for 20 minutes. The second train is to arrive half an hour after the first train leaves the station, and this second train will stay in the station for a quarter of the amount of time that the first train stayed in the station. The third train is to arrive an hour after the second train leaves the station, and this third train is to leave the station immediately after it arrives.  The fourth train will arrive 20 minutes after the third train leaves, and this is the train Paul will board.  In total, how long, in minutes, will Paul wait for his train?\n",
            "\n",
            "Longest answer (302 tokens):\n",
            "First calculate the gross annual salary for Job A: 2000 hours * $15/hour = $<<2000*15=30000>>30,000\n",
            "Next, calculate the amount of taxes Nick pays at Job A by multiplying his net salary by the 20% tax rate: .2 * $30,000 = $<<30000*.2=6000>>6,000\n",
            "Now subtract Nick's taxes from his net pay to find his gross pay at Job A: $30,000 - $6,000 = $<<30000-6000=24000>>24,000\n",
            "Now subtract Nick's property taxes from his gross income at Job B: $42,000 - $6,000 = $<<42000-6000=36000>>36,000\n",
            "Now multiply Nick's income after property tax by 10% to find his income tax at Job B: $36,000 * 10% = $<<36000*10*.01=3600>>3,600\n",
            "Now subtract the income tax amount from Nick's earnings after property tax to find his net income at Job B: $36,000 - $3,600 = $<<36000-3600=32400>>32,400\n",
            "Now subtract the net income from the lower-paying job (A) from the net income from the higher-paying job (B): $32,400 - $24,000 = $<<32400-24000=8400>>8,400\n",
            "#### 8400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_data = pd.read_csv(os.path.join(base_path, \"main_train.csv\"))\n",
        "test_data = pd.read_csv(os.path.join(base_path, \"main_test.csv\"))\n",
        "\n",
        "# Count tokens per question for curriculum learning\n",
        "train_data[\"question_tokens\"] = train_data[\"question\"].apply(\n",
        "    lambda x: len(tokenizer.encode(str(x)))\n",
        ")\n",
        "\n",
        "# Select 10% shortest questions for SFT\n",
        "sft_data = train_data.nsmallest(int(0.1 * len(train_data)), \"question_tokens\")\n",
        "grpo_data = train_data.drop(sft_data.index)  # Save rest for GRPO\n",
        "grpo_data = grpo_data.sample(frac=0.025, random_state=42)\n",
        "\n",
        "def format_answer(answer):\n",
        "    \"\"\"Format answer with proper tokens\"\"\"\n",
        "    answer = answer.strip()\n",
        "    # Ensure #### is properly spaced\n",
        "    answer = re.sub(r'####(\\S)', r'#### \\1', answer)\n",
        "    # Replace calculation format if needed\n",
        "    answer = re.sub(r'<<(.*?)>>', r'<<\\1>>', answer)\n",
        "    if not answer.endswith(tokenizer.eos_token):\n",
        "        answer += f\" {tokenizer.eos_token}\"\n",
        "    return answer\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    \"\"\"Format input-output pairs with proper tokens\"\"\"\n",
        "    combined_texts = []\n",
        "    for q, a in zip(examples[\"question\"], examples[\"answer\"]):\n",
        "        formatted_answer = format_answer(a)\n",
        "        # Use proper tokens for chat format\n",
        "        prompt = (f\"{tokenizer.bos_token}{q.strip()}\"\n",
        "                 f\"{tokenizer.sep_token}{formatted_answer}\")\n",
        "        combined_texts.append(prompt)\n",
        "\n",
        "    # Tokenize with proper padding and truncation\n",
        "    return tokenizer(\n",
        "        combined_texts,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\",\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=False  # Not needed for GPT-2\n",
        "    )\n",
        "\n",
        "# Create datasets for SFT<>\n",
        "sft_train_dataset = Dataset.from_pandas(sft_data)\n",
        "sft_train_dataset = sft_train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=sft_train_dataset.column_names  # Remove original columns\n",
        ")\n",
        "\n",
        "# Create validation dataset\n",
        "test_data = test_data.sample(frac=0.1, random_state=42)\n",
        "sft_val_dataset = Dataset.from_pandas(test_data)\n",
        "sft_val_dataset = sft_val_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=sft_val_dataset.column_names\n",
        ")\n",
        "\n",
        "# Save GRPO data for later\n",
        "grpo_dataset = Dataset.from_pandas(grpo_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b95c80e02efa470088ba30768da82a1e",
            "d7f504f708e94eb48b47e37cfc1c1ada",
            "196835a82a754594bfb1619689cb4a77",
            "cf7fbb3198f9474da841e6ad0ef2b183",
            "e4ef5790c25744feb37c07ff3911954f",
            "246f6e195a7148e784c622deb402d291",
            "b9daf38e138b437ea165cfe95a0635b6",
            "e71049b0cd944d0bb73c510514f3ee2a",
            "38e64d1d922b43d08ab12dcc6c3d1281",
            "f7e77fa1c989452e8717046d103edcd2",
            "4f9c612d464749ce8cca0d8916ce78ec",
            "55c7bfb6591f44fe9d9802b196732dc4",
            "a11bbb2ce52642c1843ac2d939b3478f",
            "778e656fe12246fcae6cf68cc28c3644",
            "ed84bb12d530497ea54b6ef0711a9935",
            "5ca21cec12d8465c99757b6aee11db29",
            "61a0992804824abcb357e7a22c193eb0",
            "ef51f47adb9446d49692f49ccee32e9b",
            "57122d3022fb4747ba63c7688de96256",
            "e24e4ebdb8d54cba987b89a3288049b5",
            "b7564418e1da4e5ca4648c504f42ee48",
            "4fccd155e23c48d19d8bc2de33e0f100"
          ]
        },
        "id": "AkmI11fWC_ta",
        "outputId": "1bd52c6c-88e9-4082-a2dd-476187294c92"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/747 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b95c80e02efa470088ba30768da82a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55c7bfb6591f44fe9d9802b196732dc4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.eos_token, tokenizer.eos_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI4qS8gJh0Tr",
        "outputId": "dc8c27d0-ff3c-4448-8421-e8932b743bdf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_end|> 50259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Training setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=4,\n",
        "    eval_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=1,\n",
        "    logging_first_step=True,\n",
        "    dataloader_drop_last=True,\n",
        "    save_strategy=\"epoch\"  # Add this to save the model after SFT\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# 6) Custom metric & utilities\n",
        "def remove_excess_after_answer(text):\n",
        "    \"\"\"Removes everything after the first '#### <answer>' (with a space).\"\"\"\n",
        "    match = re.search(r\"####\\s+(\\S+)\", text)  # Requires at least one space\n",
        "    if match:\n",
        "        prefix = text[:match.start()]\n",
        "        return prefix + \"#### \" + match.group(1)  # Re-add the space for consistency\n",
        "    return text\n",
        "\n",
        "def custom_compute_metrics(eval_preds):\n",
        "    \"\"\"Computes accuracy based on '#### <answer>' (number before eos).\"\"\"\n",
        "    logits, labels = eval_preds\n",
        "    pred_ids = np.argmax(logits, axis=-1)\n",
        "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=False)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=False)\n",
        "\n",
        "    correct = 0\n",
        "    total = len(decoded_preds)\n",
        "\n",
        "    for pred_text, label_text in zip(decoded_preds, decoded_labels):\n",
        "        match_pred = re.search(r\"####\\s*(\\d+)\\s*<\\|im_end\\|>\", pred_text) # Number before eos\n",
        "        match_label = re.search(r\"####\\s*(\\d+)\\s*<\\|im_end\\|>\", label_text) # Number before eos\n",
        "\n",
        "        if match_pred and match_label:\n",
        "            answer_pred = match_pred.group(1).strip()\n",
        "            answer_label = match_label.group(1).strip()\n",
        "            if answer_pred == answer_label:\n",
        "                correct += 1\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    return {\"custom_accuracy\": accuracy}\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=sft_train_dataset,\n",
        "    eval_dataset=sft_val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=custom_compute_metrics\n",
        ")\n",
        "\n",
        "# 7) Train\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "JrdPjfMh2TGo",
        "outputId": "201dc8a9-1761-4adf-cdf6-54633e650749"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [46/46 01:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Custom Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.448000</td>\n",
              "      <td>3.477013</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.741700</td>\n",
              "      <td>3.154286</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=46, training_loss=4.739146398461384, metrics={'train_runtime': 81.9947, 'train_samples_per_second': 18.221, 'train_steps_per_second': 0.561, 'total_flos': 153998991360000.0, 'train_loss': 4.739146398461384, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Free-form inference (Batched)\n",
        "batch_size = 16\n",
        "eos_token_id = tokenizer.eos_token_id  # Using proper eos token\n",
        "\n",
        "questions = test_data[\"question\"].tolist()\n",
        "references = test_data[\"answer\"].tolist()\n",
        "\n",
        "rows = []\n",
        "num_batches = math.ceil(len(questions) / batch_size)\n",
        "\n",
        "for b_idx in tqdm(range(num_batches), desc=\"Batched Inference\"):\n",
        "    start_idx = b_idx * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "\n",
        "    batch_questions = questions[start_idx:end_idx]\n",
        "    batch_refs = references[start_idx:end_idx]\n",
        "\n",
        "    # Build prompt with proper tokens\n",
        "    batch_prompts = [\n",
        "        f\"{tokenizer.bos_token}{q}{tokenizer.sep_token}\"\n",
        "        for q in batch_questions\n",
        "    ]\n",
        "\n",
        "    # Rest of tokenization and generation stays the same\n",
        "    encoded_batch = tokenizer(\n",
        "        batch_prompts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    encoded_batch = {k: v.to(model.device) for k, v in encoded_batch.items()}\n",
        "\n",
        "    # Generate\n",
        "    output_ids = model.generate(\n",
        "        input_ids=encoded_batch[\"input_ids\"],\n",
        "        attention_mask=encoded_batch[\"attention_mask\"],\n",
        "        eos_token_id=eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    # Rest remains the same\n",
        "    for q_text, ref, out_ids in zip(batch_questions, batch_refs, output_ids):\n",
        "        gen_text = tokenizer.decode(out_ids)\n",
        "        cleaned_prediction = remove_excess_after_answer(gen_text)\n",
        "\n",
        "        rows.append({\n",
        "            \"question\": q_text,\n",
        "            \"prediction\": cleaned_prediction,\n",
        "            \"reference\": ref\n",
        "        })\n",
        "\n",
        "inference_df = pd.DataFrame(rows)\n",
        "inference_df.to_csv(\"test_predictions_freeform.csv\", index=False)\n",
        "print(\"Saved batched free-form generation results to 'test_predictions_freeform.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1b02030791ce46488e2981aae2df618d",
            "c9e9b9ccce4243c0b75d4ab2dacf1e29",
            "794b83567f7442c9b969215fdc571e5b",
            "542ddd69dbda4b25a7947e491b589eb9",
            "6334a32c6a824af29b10a150ae368868",
            "e9446ecdd8164ea9a1fbd2c1b10bf2f4",
            "de1fc501662a4890951041fd1a3dbfe1",
            "0d9ef8ed14f749d1bc8ef395dbdf9566",
            "19c7b92a6e534a8d952f86ab5553edd8",
            "ca0257879afb4ed0b664179c014a44db",
            "d15eb8d1dc78404293b2d57fcd5ff1f2"
          ]
        },
        "id": "HtuFUFf1C8Ag",
        "outputId": "5787f000-3696-4217-8a36-dffcbf68cdef"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batched Inference:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b02030791ce46488e2981aae2df618d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved batched free-form generation results to 'test_predictions_freeform.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from typing import List, Dict, Any,Tuple\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import List, Callable"
      ],
      "metadata": {
        "id": "aj8ndgi75Qzq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGRPOTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: AutoModelForCausalLM,\n",
        "        ref_model: AutoModelForCausalLM,\n",
        "        tokenizer: AutoTokenizer,\n",
        "        reward_funcs: List[Callable],\n",
        "        num_generations: int = 4,\n",
        "        learning_rate: float = 1e-6,\n",
        "        beta: float = 0.04,\n",
        "        max_prompt_length: int = 512,\n",
        "        max_completion_length: int = 256,\n",
        "        temperature: float = 0.9\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.ref_model = ref_model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.reward_funcs = reward_funcs\n",
        "        self.num_generations = num_generations\n",
        "        self.optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "        self.beta = beta\n",
        "        self.max_prompt_length = max_prompt_length\n",
        "        self.max_completion_length = max_completion_length\n",
        "        self.temperature = temperature\n",
        "\n",
        "        # Generation config\n",
        "        self.generation_config = GenerationConfig(\n",
        "            max_new_tokens=self.max_completion_length,\n",
        "            do_sample=True,\n",
        "            temperature=self.temperature,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    def _prepare_inputs(self, prompts: List[dict]) -> dict:\n",
        "        \"\"\"Format prompts with math-specific tokens and prepare for model\"\"\"\n",
        "        # Format prompts with our special tokens\n",
        "        prompt_texts = [\n",
        "            f\"{self.tokenizer.bos_token}{p['prompt']}{self.tokenizer.sep_token}\"\n",
        "            for p in prompts\n",
        "        ]\n",
        "\n",
        "        # Tokenize with right padding\n",
        "        prompt_inputs = self.tokenizer(\n",
        "            prompt_texts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_prompt_length,\n",
        "            add_special_tokens=False\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        return prompt_inputs\n",
        "\n",
        "    def generate_completions(self, prompts: List[dict]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Generate multiple completions per prompt with proper masking and padding\"\"\"\n",
        "        prompt_inputs = self._prepare_inputs(prompts)\n",
        "        prompt_ids = prompt_inputs[\"input_ids\"]\n",
        "        prompt_mask = prompt_inputs[\"attention_mask\"]\n",
        "\n",
        "        all_completions = []\n",
        "        completion_masks = []\n",
        "\n",
        "        # Generate multiple times per prompt\n",
        "        for _ in range(self.num_generations):\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    input_ids=prompt_ids,\n",
        "                    attention_mask=prompt_mask,\n",
        "                    generation_config=self.generation_config,\n",
        "                    return_dict_in_generate=True,\n",
        "                    output_scores=True,\n",
        "                    early_stopping=True,\n",
        "                )\n",
        "\n",
        "                completion_ids = outputs.sequences[:, prompt_ids.shape[1]:]\n",
        "\n",
        "                # Find max length in this batch of generations\n",
        "                max_len = completion_ids.shape[1]\n",
        "\n",
        "                # Create completion mask (handling EOS tokens)\n",
        "                is_eos = completion_ids == self.tokenizer.eos_token_id\n",
        "                eos_indices = torch.argmax(is_eos.float(), dim=1)\n",
        "                eos_indices[~is_eos.any(1)] = completion_ids.shape[1] - 1\n",
        "                completion_mask = torch.arange(completion_ids.shape[1], device=completion_ids.device)[None, :] <= eos_indices[:, None]\n",
        "\n",
        "                all_completions.append(completion_ids)\n",
        "                completion_masks.append(completion_mask)\n",
        "\n",
        "        # Find the maximum length across all generations\n",
        "        max_length = max(comp.shape[1] for comp in all_completions)\n",
        "\n",
        "        # Pad all completions to the maximum length\n",
        "        padded_completions = []\n",
        "        padded_masks = []\n",
        "\n",
        "        for comp, mask in zip(all_completions, completion_masks):\n",
        "            if comp.shape[1] < max_length:\n",
        "                # Pad completions\n",
        "                padding = torch.full(\n",
        "                    (comp.shape[0], max_length - comp.shape[1]),\n",
        "                    self.tokenizer.pad_token_id,\n",
        "                    dtype=comp.dtype,\n",
        "                    device=comp.device\n",
        "                )\n",
        "                padded_comp = torch.cat([comp, padding], dim=1)\n",
        "\n",
        "                # Pad masks\n",
        "                mask_padding = torch.zeros(\n",
        "                    (mask.shape[0], max_length - mask.shape[1]),\n",
        "                    dtype=mask.dtype,\n",
        "                    device=mask.device\n",
        "                )\n",
        "                padded_mask = torch.cat([mask, mask_padding], dim=1)\n",
        "            else:\n",
        "                padded_comp = comp\n",
        "                padded_mask = mask\n",
        "\n",
        "            padded_completions.append(padded_comp)\n",
        "            padded_masks.append(padded_mask)\n",
        "\n",
        "        return torch.stack(padded_completions, dim=1), torch.stack(padded_masks, dim=1)\n",
        "\n",
        "    def compute_rewards(self, prompts: List[dict], completions: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute and normalize rewards group-wise\"\"\"\n",
        "        # Flatten completions for reward computation\n",
        "        batch_size = completions.shape[0]\n",
        "        num_generations = completions.shape[1]\n",
        "\n",
        "        # Create flattened list of prompts to match completion structure\n",
        "        flattened_prompts = []\n",
        "        for prompt in prompts:\n",
        "            flattened_prompts.extend([prompt] * num_generations)\n",
        "\n",
        "        # Convert completions to texts\n",
        "        completion_texts = []\n",
        "        for i in range(batch_size):\n",
        "            for j in range(num_generations):\n",
        "                text = self.tokenizer.decode(completions[i,j], skip_special_tokens=False)\n",
        "                completion_texts.append(text)\n",
        "\n",
        "        # Get rewards from all functions\n",
        "        total_rewards = torch.zeros(len(completion_texts), device=self.model.device)\n",
        "        for reward_func in self.reward_funcs:\n",
        "            rewards = reward_func(prompts=flattened_prompts, completions=completion_texts)\n",
        "            total_rewards += torch.tensor(rewards, device=self.model.device)\n",
        "\n",
        "        # Reshape rewards back to (batch_size, num_generations)\n",
        "        rewards = total_rewards.view(batch_size, num_generations)\n",
        "\n",
        "        # Normalize group-wise\n",
        "        mean_rewards = rewards.mean(dim=1, keepdim=True)\n",
        "        std_rewards = rewards.std(dim=1, keepdim=True)\n",
        "        advantages = (rewards - mean_rewards) / (std_rewards + 1e-8)\n",
        "\n",
        "        return advantages\n",
        "\n",
        "    def compute_logprobs(self, model: AutoModelForCausalLM, input_ids: torch.Tensor, attention_mask: torch.Tensor, logits_to_keep: int) -> torch.Tensor:\n",
        "        \"\"\"Compute per-token log probabilities with proper masking\"\"\"\n",
        "        with torch.set_grad_enabled(model is self.model):\n",
        "            # Get logits for completion portion\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits[:, :-1, :]  # Remove last prediction\n",
        "\n",
        "            # Get target tokens\n",
        "            targets = input_ids[:, 1:]  # Shift right for next token prediction\n",
        "\n",
        "            # Keep only completion portion with proper size\n",
        "            logits = logits[:, -logits_to_keep:]\n",
        "            targets = targets[:, -logits_to_keep:]\n",
        "\n",
        "            # Compute log probabilities\n",
        "            log_probs = torch.log_softmax(logits, dim=-1)\n",
        "            token_log_probs = log_probs.gather(-1, targets.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "            return token_log_probs\n",
        "\n",
        "    def train_step(self, batch: List[dict]):\n",
        "        # Generate completions and get masks\n",
        "        completions, completion_masks = self.generate_completions(batch)\n",
        "\n",
        "        # Get rewards and advantages\n",
        "        advantages = self.compute_rewards(batch, completions)\n",
        "\n",
        "        # Prepare for loss computation\n",
        "        total_loss = 0\n",
        "\n",
        "        for i in range(completions.shape[0]):  # For each prompt\n",
        "            for j in range(completions.shape[1]):  # For each completion\n",
        "                # Concatenate prompt and completion\n",
        "                prompt_ids = self._prepare_inputs(batch)[\"input_ids\"][i:i+1]  # Keep batch dimension\n",
        "                completion_ids = completions[i,j:j+1]  # Keep batch dimension\n",
        "                completion_mask = completion_masks[i,j:j+1]\n",
        "\n",
        "                input_ids = torch.cat([prompt_ids, completion_ids], dim=1)\n",
        "                attention_mask = torch.cat([\n",
        "                    torch.ones_like(prompt_ids),\n",
        "                    completion_mask\n",
        "                ], dim=1)\n",
        "\n",
        "                logits_to_keep = completion_ids.size(1)\n",
        "\n",
        "                # Get log probs for both policy and reference model\n",
        "                policy_log_probs = self.compute_logprobs(\n",
        "                    self.model, input_ids, attention_mask, logits_to_keep\n",
        "                )\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    ref_log_probs = self.compute_logprobs(\n",
        "                        self.ref_model, input_ids, attention_mask, logits_to_keep\n",
        "                    )\n",
        "\n",
        "                # Make sure all tensors have the same size\n",
        "                policy_log_probs = policy_log_probs[:, :logits_to_keep-1]  # Adjust for next token prediction\n",
        "                ref_log_probs = ref_log_probs[:, :logits_to_keep-1]\n",
        "                mask = completion_mask[:, :logits_to_keep-1]  # Adjust mask to match\n",
        "\n",
        "                # Compute KL divergence with size-matched tensors\n",
        "                kl = torch.exp(ref_log_probs - policy_log_probs) - (ref_log_probs - policy_log_probs) - 1\n",
        "\n",
        "                # Compute policy gradient loss with KL penalty\n",
        "                per_token_loss = torch.exp(policy_log_probs - policy_log_probs.detach()) * advantages[i,j]\n",
        "                per_token_loss = -(per_token_loss - self.beta * kl)\n",
        "\n",
        "                # Average loss over non-padded tokens using matched sizes\n",
        "                loss = ((per_token_loss * mask).sum(dim=1) / (mask.sum(dim=1) + 1e-8)).mean()\n",
        "                total_loss += loss\n",
        "\n",
        "        # Average loss across batch and optimize\n",
        "        loss = total_loss / (completions.shape[0] * completions.shape[1])\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss.item()"
      ],
      "metadata": {
        "id": "C97fZfo33wQ_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_final_answer(text: str) -> str | None:\n",
        "    \"\"\"Extract the final answer after ####\"\"\"\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    answer = text.split(\"####\")[1].strip()\n",
        "    return answer.replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
        "\n",
        "def extract_calculations(text: str) -> List[tuple[str, str]]:\n",
        "    \"\"\"Extract all calculations within <<>> tags, returning (expression, result) pairs\"\"\"\n",
        "    pattern = r\"<<(.*?)=(.*?)>>\"\n",
        "    matches = re.finditer(pattern, text)\n",
        "    return [(match.group(1).strip(), match.group(2).strip()) for match in matches]\n",
        "\n",
        "def evaluate_expression(expr: str) -> float:\n",
        "    \"\"\"Safely evaluate a mathematical expression\"\"\"\n",
        "    # Remove any commas and convert to plain numbers\n",
        "    expr = expr.replace(\",\", \"\").replace(\"$\", \"\")\n",
        "    try:\n",
        "        return float(eval(expr))\n",
        "    except:\n",
        "        return float('nan')\n",
        "\n",
        "def format_reward_func(completions: List[str], **kwargs) -> List[float]:\n",
        "    \"\"\"\n",
        "    Reward proper formatting:\n",
        "    - Presence of calculations in <<>> format\n",
        "    - Presence of #### for final answer\n",
        "    - Presence of the EOS token (e.g., <|im_end|>) at the end of the completion\n",
        "    - General structure\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for completion in completions:\n",
        "        score = 0.0\n",
        "\n",
        "        # Check for presence of calculations in <<>> format\n",
        "        if re.search(r\"<<.*?=.*?>>\", completion):\n",
        "            score += 0.2\n",
        "\n",
        "        # Check for the final answer marker '####'\n",
        "        if \"####\" in completion:\n",
        "            score += 0.2\n",
        "\n",
        "            # Check if there's exactly one '####'\n",
        "            if completion.count(\"####\") == 1:\n",
        "                score += 0.1\n",
        "\n",
        "            # Check if calculations come before the final answer marker\n",
        "            parts = completion.split(\"####\")\n",
        "            if len(parts) == 2 and \"<<\" in parts[0]:\n",
        "                score += 0.2\n",
        "\n",
        "        # Check for the presence of the EOS token at the end.\n",
        "        # Either hardcode \"<|im_end|>\" or use tokenizer.eos_token if available.\n",
        "        eos_token = \"<|im_end|>\"  # or, if available: eos_token = tokenizer.eos_token\n",
        "        if completion.strip().endswith(eos_token):\n",
        "            score += 0.2\n",
        "\n",
        "        rewards.append(score)\n",
        "\n",
        "    return rewards\n",
        "\n",
        "def calculation_reward_func(completions: List[str], **kwargs) -> List[float]:\n",
        "    \"\"\"\n",
        "    Reward correct intermediate calculations:\n",
        "    - Each calculation within <<>> must be mathematically correct\n",
        "    - Format should be expression=result\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for completion in completions:\n",
        "        score = 0.0\n",
        "        calculations = extract_calculations(completion)\n",
        "\n",
        "        if not calculations:\n",
        "            rewards.append(0.0)\n",
        "            continue\n",
        "\n",
        "        total_calcs = len(calculations)\n",
        "        correct_calcs = 0\n",
        "\n",
        "        for expr, result in calculations:\n",
        "            try:\n",
        "                expected = evaluate_expression(expr)\n",
        "                actual = evaluate_expression(result)\n",
        "                if abs(expected - actual) < 0.01:  # Allow small floating point differences\n",
        "                    correct_calcs += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if total_calcs > 0:\n",
        "            score = (correct_calcs / total_calcs) * 0.5  # Max 0.5 points for calculations\n",
        "\n",
        "        rewards.append(score)\n",
        "\n",
        "    return rewards\n",
        "\n",
        "def answer_correctness_reward_func(completions: List[str], answer: List[str], **kwargs) -> List[float]:\n",
        "    \"\"\"\n",
        "    Reward correct final answer:\n",
        "    - Answer after #### must match the expected answer\n",
        "    - Handles number formatting (commas, spaces, etc.)\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for completion, expected in zip(completions, answer):\n",
        "        score = 0.0\n",
        "\n",
        "        extracted = extract_final_answer(completion)\n",
        "        if extracted is not None and expected is not None:\n",
        "            # Clean up both answers for comparison\n",
        "            extracted = extracted.replace(\" \", \"\").replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
        "            expected = str(expected).replace(\" \", \"\").replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
        "\n",
        "            try:\n",
        "                # Try numerical comparison first\n",
        "                if abs(float(extracted) - float(expected)) < 0.01:\n",
        "                    score = 1.0\n",
        "            except:\n",
        "                # Fallback to string comparison\n",
        "                if extracted == expected:\n",
        "                    score = 1.0\n",
        "\n",
        "        rewards.append(score)\n",
        "\n",
        "    return rewards\n",
        "\n",
        "def combined_reward_func(prompts: List[dict], completions: List[str], **kwargs) -> List[float]:\n",
        "    \"\"\"Modified signature to match GRPO expectations\"\"\"\n",
        "    answers = [p[\"answer\"] for p in prompts]  # Extract answers from prompts\n",
        "    format_rewards = format_reward_func(completions)\n",
        "    calc_rewards = calculation_reward_func(completions)\n",
        "    answer_rewards = answer_correctness_reward_func(completions, answers)\n",
        "\n",
        "    combined_rewards = []\n",
        "    for f, c, a in zip(format_rewards, calc_rewards, answer_rewards):\n",
        "        reward = (f * 0.05) + (c * 0.05) + (a * 0.9)\n",
        "        combined_rewards.append(reward)\n",
        "\n",
        "    return combined_rewards"
      ],
      "metadata": {
        "id": "iL6nLedA5MH_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import copy"
      ],
      "metadata": {
        "id": "hn4hp9g7cWZA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "with torch.cuda.device('cuda'):\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "guvKt5G3F6nM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting GRPO training...\")\n",
        "grpo_model = model  # use the SFT-trained model\n",
        "grpo_ref_model = copy.deepcopy(model)\n",
        "grpo_ref_model.eval()  # ensure the reference model is in evaluation mode\n",
        "for param in grpo_ref_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Prepare GRPO dataset for training\n",
        "# ------------------------------------------------------------------------------\n",
        "# grpo_dataset was created earlier as Dataset.from_pandas(grpo_data)\n",
        "# Convert the dataset to a pandas DataFrame, rename \"question\" to \"prompt\",\n",
        "# and then convert it to a list of dictionaries.\n",
        "grpo_df = grpo_dataset.to_pandas()\n",
        "grpo_df.rename(columns={\"question\": \"prompt\"}, inplace=True)\n",
        "grpo_examples = grpo_df.to_dict(orient=\"records\")\n",
        "# Each element in grpo_examples is now a dict like: {\"prompt\": <question>, \"answer\": <answer>}\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Create the GRPO trainer\n",
        "# ------------------------------------------------------------------------------\n",
        "# (Assuming SimpleGRPOTrainer and all reward functions were defined earlier)\n",
        "grpo_trainer = SimpleGRPOTrainer(\n",
        "    model=grpo_model,\n",
        "    ref_model=grpo_ref_model,\n",
        "    tokenizer=tokenizer,\n",
        "    reward_funcs=[combined_reward_func],  # use your combined reward function\n",
        "    num_generations=8,\n",
        "    learning_rate=1e-6,\n",
        "    beta=0.04,\n",
        "    temperature=0.9,\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# GRPO Training Loop with tqdm\n",
        "# ------------------------------------------------------------------------------\n",
        "num_epochs = 1      # Adjust the number of GRPO epochs as needed\n",
        "batch_size = 1      # GRPO batch size (number of prompts per step)\n",
        "\n",
        "print(\"Starting GRPO training...\")\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    # Shuffle the GRPO examples at the beginning of each epoch\n",
        "    random.shuffle(grpo_examples)\n",
        "    num_batches = math.ceil(len(grpo_examples) / batch_size)\n",
        "\n",
        "    # Use tqdm for batch-level progress within the epoch.\n",
        "    for batch_idx in tqdm(range(num_batches), desc=\"Batches\", leave=False):\n",
        "        start = batch_idx * batch_size\n",
        "        batch = grpo_examples[start: start + batch_size]\n",
        "        loss = grpo_trainer.train_step(batch)\n",
        "        # Using tqdm.write to log without interfering with the progress bar.\n",
        "        tqdm.write(f\"Epoch {epoch+1}/{num_epochs} - Batch {batch_idx+1}/{num_batches} - Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"GRPO training completed.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Save the GRPO-trained model and tokenizer\n",
        "# ------------------------------------------------------------------------------\n",
        "output_dir = \"./grpo_model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "grpo_model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"GRPO-trained model saved to '{output_dir}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "21a9e5d55ebb4de09eda49239ca6006d",
            "a9c6987b89d3443780b7b149aa93cd2e",
            "f0c7a50a03934ae59d33c20715003637",
            "9a2a2cf8d483493aafafcc06930040fe",
            "6cf438d8266342d2af492310588716a8",
            "d75b81658284476f9c852380ef742a7e",
            "015a824aab784952afd25f0421c00677",
            "8eafabd003044cb09519679cdd2ee08a",
            "51b6af7bbd95497a9b71a9631d522dc4",
            "16b9bcd8fc8944f0aec55f97f7fdf3e4",
            "0cb9969b5aea402cb43b5de2757a24a1",
            "787e59b8472146d6bdf9fd179ef323a0",
            "8eb57d47d0f2413787c0e8ea995c38e9",
            "d58b1433dea24fd0a8e1318d53c8e3fc",
            "a736e02d13cd4f71ab88ce8a37e45116",
            "59d1e560f5d94004a9bface2631b33d8",
            "c19b85adcf104ea88f0231a36cf53039",
            "aa44c371c99f4d659f7f94a65e537d5d",
            "c12181b4be5943d9a865ef345906a3f9",
            "91197708d6aa41e293db8f2516916b06",
            "b93bedfa389b425792546b74b7cec9e7",
            "294d3e0083224a31baa3e72157f5e459"
          ]
        },
        "id": "gf09KxpUYdC9",
        "outputId": "3875ee63-2088-45e9-849a-4d21194423d0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GRPO training...\n",
            "Starting GRPO training...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21a9e5d55ebb4de09eda49239ca6006d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "787e59b8472146d6bdf9fd179ef323a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/168 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:677: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 - Batch 1/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 2/168 - Loss: -0.0000\n",
            "Epoch 1/1 - Batch 3/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 4/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 5/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 6/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 7/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 8/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 9/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 10/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 11/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 12/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 13/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 14/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 15/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 16/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 17/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 18/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 19/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 20/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 21/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 22/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 23/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 24/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 25/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 26/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 27/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 28/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 29/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 30/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 31/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 32/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 33/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 34/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 35/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 36/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 37/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 38/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 39/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 40/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 41/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 42/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 43/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 44/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 45/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 46/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 47/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 48/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 49/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 50/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 51/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 52/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 53/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 54/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 55/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 56/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 57/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 58/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 59/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 60/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 61/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 62/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 63/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 64/168 - Loss: 0.0000\n",
            "Epoch 1/1 - Batch 65/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 66/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 67/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 68/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 69/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 70/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 71/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 72/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 73/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 74/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 75/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 76/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 77/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 78/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 79/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 80/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 81/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 82/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 83/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 84/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 85/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 86/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 87/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 88/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 89/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 90/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 91/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 92/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 93/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 94/168 - Loss: 0.0004\n",
            "Epoch 1/1 - Batch 95/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 96/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 97/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 98/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 99/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 100/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 101/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 102/168 - Loss: 0.0003\n",
            "Epoch 1/1 - Batch 103/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 104/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 105/168 - Loss: 0.0002\n",
            "Epoch 1/1 - Batch 106/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 107/168 - Loss: 0.0006\n",
            "Epoch 1/1 - Batch 108/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 109/168 - Loss: 0.0004\n",
            "Epoch 1/1 - Batch 110/168 - Loss: 0.0007\n",
            "Epoch 1/1 - Batch 111/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 112/168 - Loss: 0.0008\n",
            "Epoch 1/1 - Batch 113/168 - Loss: 0.0004\n",
            "Epoch 1/1 - Batch 114/168 - Loss: 0.0001\n",
            "Epoch 1/1 - Batch 115/168 - Loss: 0.0007\n",
            "Epoch 1/1 - Batch 116/168 - Loss: 0.0008\n",
            "Epoch 1/1 - Batch 117/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 118/168 - Loss: 0.0018\n",
            "Epoch 1/1 - Batch 119/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 120/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 121/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 122/168 - Loss: 0.0012\n",
            "Epoch 1/1 - Batch 123/168 - Loss: 0.0008\n",
            "Epoch 1/1 - Batch 124/168 - Loss: 0.0016\n",
            "Epoch 1/1 - Batch 125/168 - Loss: 0.0006\n",
            "Epoch 1/1 - Batch 126/168 - Loss: 0.0021\n",
            "Epoch 1/1 - Batch 127/168 - Loss: 0.0014\n",
            "Epoch 1/1 - Batch 128/168 - Loss: 0.0013\n",
            "Epoch 1/1 - Batch 129/168 - Loss: 0.0019\n",
            "Epoch 1/1 - Batch 130/168 - Loss: 0.0026\n",
            "Epoch 1/1 - Batch 131/168 - Loss: 0.0012\n",
            "Epoch 1/1 - Batch 132/168 - Loss: 0.0019\n",
            "Epoch 1/1 - Batch 133/168 - Loss: 0.0015\n",
            "Epoch 1/1 - Batch 134/168 - Loss: 0.0030\n",
            "Epoch 1/1 - Batch 135/168 - Loss: 0.0010\n",
            "Epoch 1/1 - Batch 136/168 - Loss: 0.0020\n",
            "Epoch 1/1 - Batch 137/168 - Loss: 0.0007\n",
            "Epoch 1/1 - Batch 138/168 - Loss: 0.0016\n",
            "Epoch 1/1 - Batch 139/168 - Loss: 0.0011\n",
            "Epoch 1/1 - Batch 140/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 141/168 - Loss: 0.0007\n",
            "Epoch 1/1 - Batch 142/168 - Loss: 0.0024\n",
            "Epoch 1/1 - Batch 143/168 - Loss: 0.0009\n",
            "Epoch 1/1 - Batch 144/168 - Loss: 0.0013\n",
            "Epoch 1/1 - Batch 145/168 - Loss: 0.0005\n",
            "Epoch 1/1 - Batch 146/168 - Loss: 0.0013\n",
            "Epoch 1/1 - Batch 147/168 - Loss: 0.0015\n",
            "Epoch 1/1 - Batch 148/168 - Loss: 0.0023\n",
            "Epoch 1/1 - Batch 149/168 - Loss: 0.0012\n",
            "Epoch 1/1 - Batch 150/168 - Loss: 0.0022\n",
            "Epoch 1/1 - Batch 151/168 - Loss: 0.0015\n",
            "Epoch 1/1 - Batch 152/168 - Loss: 0.0014\n",
            "Epoch 1/1 - Batch 153/168 - Loss: 0.0022\n",
            "Epoch 1/1 - Batch 154/168 - Loss: 0.0022\n",
            "Epoch 1/1 - Batch 155/168 - Loss: 0.0024\n",
            "Epoch 1/1 - Batch 156/168 - Loss: 0.0020\n",
            "Epoch 1/1 - Batch 157/168 - Loss: 0.0020\n",
            "Epoch 1/1 - Batch 158/168 - Loss: 0.0024\n",
            "Epoch 1/1 - Batch 159/168 - Loss: 0.0023\n",
            "Epoch 1/1 - Batch 160/168 - Loss: 0.0020\n",
            "Epoch 1/1 - Batch 161/168 - Loss: 0.0027\n",
            "Epoch 1/1 - Batch 162/168 - Loss: 0.0027\n",
            "Epoch 1/1 - Batch 163/168 - Loss: 0.0033\n",
            "Epoch 1/1 - Batch 164/168 - Loss: 0.0033\n",
            "Epoch 1/1 - Batch 165/168 - Loss: 0.0031\n",
            "Epoch 1/1 - Batch 166/168 - Loss: 0.0026\n",
            "Epoch 1/1 - Batch 167/168 - Loss: 0.0026\n",
            "Epoch 1/1 - Batch 168/168 - Loss: 0.0032\n",
            "GRPO training completed.\n",
            "GRPO-trained model saved to './grpo_model'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------\n",
        "# Inference Evaluation after GRPO training\n",
        "# --------------------------------------------------------------------------\n",
        "# Use the GRPO-trained model to generate predictions on the test set.\n",
        "# Here we use batched generation with the same special tokens.\n",
        "test_questions = test_data[\"question\"].tolist()\n",
        "test_references = test_data[\"answer\"].tolist()\n",
        "\n",
        "inference_rows = []\n",
        "inference_batch_size = 32  # adjust as needed\n",
        "num_inference_batches = math.ceil(len(test_questions) / inference_batch_size)\n",
        "\n",
        "print(\"Running inference on test data...\")\n",
        "for b_idx in tqdm(range(num_inference_batches), desc=\"GRPO Inference\"):\n",
        "    start_idx = b_idx * inference_batch_size\n",
        "    end_idx = start_idx + inference_batch_size\n",
        "    batch_questions = test_questions[start_idx:end_idx]\n",
        "    batch_refs = test_references[start_idx:end_idx]\n",
        "\n",
        "    # Build prompts using the same chat format as before.\n",
        "    batch_prompts = [\n",
        "        f\"{tokenizer.bos_token}{q}{tokenizer.sep_token}\"\n",
        "        for q in batch_questions\n",
        "    ]\n",
        "\n",
        "    encoded_batch = tokenizer(\n",
        "        batch_prompts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "    )\n",
        "    # Move inputs to the model device\n",
        "    encoded_batch = {k: v.to(grpo_model.device) for k, v in encoded_batch.items()}\n",
        "\n",
        "    # Generate completions using the GRPO-trained model.\n",
        "    output_ids = grpo_model.generate(\n",
        "        input_ids=encoded_batch[\"input_ids\"],\n",
        "        attention_mask=encoded_batch[\"attention_mask\"],\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        max_new_tokens=1024,\n",
        "        do_sample=False,  # or True if you prefer sampling,\n",
        "        early_stopping=True,\n",
        "    )\n",
        "\n",
        "    # Decode and clean predictions.\n",
        "    for q_text, ref_text, out_ids in zip(batch_questions, batch_refs, output_ids):\n",
        "        gen_text = tokenizer.decode(out_ids, skip_special_tokens=False)\n",
        "        cleaned_prediction = remove_excess_after_answer(gen_text)\n",
        "        inference_rows.append({\n",
        "            \"question\": q_text,\n",
        "            \"prediction\": cleaned_prediction,\n",
        "            \"reference\": ref_text\n",
        "        })\n",
        "\n",
        "# Save inference results as CSV.\n",
        "inference_df = pd.DataFrame(inference_rows)\n",
        "csv_filename = \"grpo_test_predictions.csv\"\n",
        "inference_df.to_csv(csv_filename, index=False)\n",
        "print(f\"Saved GRPO inference predictions to '{csv_filename}'.\")"
      ],
      "metadata": {
        "id": "TgsV2i-yYPN3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "fe5059e595514912a20de6fed1a229fe",
            "549e7890cdd74271885902a3ecb84257",
            "45e6318493524b4ab684a73b70dd83f9",
            "0cffbc42422641c6bf71361c45af865e",
            "2d22057591e6445d9af4e2f97307d7e1",
            "cc86fa6c31e242b793e7edb485ffb7d4",
            "f28c5b4e391c44758af0113833cf54e4",
            "22c40021d20b4174838ceab64d07159d",
            "0dd6c8ba11db4d88a6be1ce954d9505c",
            "2788ed6f018843d08627411af34dbac8",
            "e17498c6deac4efe87fb98753c00b460"
          ]
        },
        "outputId": "e09c5a5e-39e3-410c-f97c-bd3444f960f5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference on test data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GRPO Inference:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe5059e595514912a20de6fed1a229fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c9c9daa9381c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Move inputs to the model device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mencoded_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrpo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Generate completions using the GRPO-trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-c9c9daa9381c>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Move inputs to the model device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mencoded_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrpo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Generate completions using the GRPO-trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process GRPO dataset the same way as before\n",
        "grpo_train_dataset = Dataset.from_pandas(grpo_data)\n",
        "grpo_train_dataset = grpo_train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=grpo_train_dataset.column_names\n",
        ")\n",
        "\n",
        "# Training arguments for continued training\n",
        "continued_training_args = TrainingArguments(\n",
        "    output_dir=\"./results_continued\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,  # Same as before\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=4,\n",
        "    eval_accumulation_steps=4,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=1,\n",
        "    logging_first_step=True,\n",
        "    dataloader_drop_last=True,\n",
        "    save_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Initialize new trainer with GRPO data\n",
        "continued_trainer = Trainer(\n",
        "    model=trainer.model,  # Use the previously trained model\n",
        "    args=continued_training_args,\n",
        "    train_dataset=grpo_train_dataset,\n",
        "    eval_dataset=sft_val_dataset,  # Keep same validation dataset\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=custom_compute_metrics\n",
        ")\n",
        "\n",
        "# Continue training\n",
        "print(\"Starting continued training with GRPO data...\")\n",
        "continued_trainer.train()\n",
        "\n",
        "# Run inference with the continued model\n",
        "batch_size = 2\n",
        "eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "questions = test_data[\"question\"].tolist()\n",
        "references = test_data[\"answer\"].tolist()\n",
        "\n",
        "rows = []\n",
        "num_batches = math.ceil(len(questions) / batch_size)\n",
        "\n",
        "for b_idx in tqdm(range(num_batches), desc=\"Continued Model Inference\"):\n",
        "    start_idx = b_idx * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "\n",
        "    batch_questions = questions[start_idx:end_idx]\n",
        "    batch_refs = references[start_idx:end_idx]\n",
        "\n",
        "    # Build prompts\n",
        "    batch_prompts = [\n",
        "        f\"{tokenizer.bos_token}{q}{tokenizer.sep_token}\"\n",
        "        for q in batch_questions\n",
        "    ]\n",
        "\n",
        "    encoded_batch = tokenizer(\n",
        "        batch_prompts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    encoded_batch = {k: v.to(model.device) for k, v in encoded_batch.items()}\n",
        "\n",
        "    # Generate\n",
        "    output_ids = model.generate(\n",
        "        input_ids=encoded_batch[\"input_ids\"],\n",
        "        attention_mask=encoded_batch[\"attention_mask\"],\n",
        "        eos_token_id=eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    for q_text, ref, out_ids in zip(batch_questions, batch_refs, output_ids):\n",
        "        gen_text = tokenizer.decode(out_ids)\n",
        "        cleaned_prediction = remove_excess_after_answer(gen_text)\n",
        "\n",
        "        rows.append({\n",
        "            \"question\": q_text,\n",
        "            \"prediction\": cleaned_prediction,\n",
        "            \"reference\": ref\n",
        "        })\n",
        "\n",
        "# Save results\n",
        "continued_inference_df = pd.DataFrame(rows)\n",
        "continued_inference_df.to_csv(\"test_predictions_continued.csv\", index=False)\n",
        "print(\"Saved continued model predictions to 'test_predictions_continued.csv'\")\n",
        "\n",
        "# Compare initial vs continued results\n",
        "initial_df = pd.read_csv(\"test_predictions_freeform.csv\")\n",
        "continued_df = pd.read_csv(\"test_predictions_continued.csv\")\n",
        "\n",
        "print(\"\\nResults Comparison:\")\n",
        "print(\"Initial Model Results:\")\n",
        "initial_accuracy = custom_compute_metrics({\"predictions\": initial_df[\"prediction\"].tolist(),\n",
        "                                         \"references\": initial_df[\"reference\"].tolist()})\n",
        "print(f\"Accuracy: {initial_accuracy['custom_accuracy']:.4f}\")\n",
        "\n",
        "print(\"\\nContinued Model Results:\")\n",
        "continued_accuracy = custom_compute_metrics({\"predictions\": continued_df[\"prediction\"].tolist(),\n",
        "                                           \"references\": continued_df[\"reference\"].tolist()})\n",
        "print(f\"Accuracy: {continued_accuracy['custom_accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "maPg_xB0Gx1G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}